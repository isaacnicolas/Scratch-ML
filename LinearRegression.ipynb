{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgw79CWOgwwEvnoj6x6ENu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["####**Imports**"],"metadata":{"id":"oumkc-9RhH80"}},{"cell_type":"code","execution_count":29,"metadata":{"id":"MjMQfw7XhEjD","executionInfo":{"status":"ok","timestamp":1687628343651,"user_tz":-120,"elapsed":244,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","source":["## **Data**"],"metadata":{"id":"25aLiICSnxST"}},{"cell_type":"markdown","source":["We will be using the https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html dataset to test the model."],"metadata":{"id":"wA0UwzcukShY"}},{"cell_type":"code","source":["# Load the California Housing dataset\n","data = fetch_california_housing()"],"metadata":{"id":"jgVaNEvwnw3P","executionInfo":{"status":"ok","timestamp":1687628343966,"user_tz":-120,"elapsed":6,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into features (X) and target variable (y)\n","X = data.data\n","y = data.target"],"metadata":{"id":"SAfLbDs_MDLb","executionInfo":{"status":"ok","timestamp":1687628343966,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler()\n","\n","# Fit the scaler to the features\n","scaler.fit(X)\n","\n","# Perform feature scaling on the features\n","X_scaled = scaler.transform(X)"],"metadata":{"id":"eOKbEpMvTXxb","executionInfo":{"status":"ok","timestamp":1687628343967,"user_tz":-120,"elapsed":6,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Print the shapes of the resulting sets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtNU8NXZo3GE","executionInfo":{"status":"ok","timestamp":1687628343967,"user_tz":-120,"elapsed":6,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}},"outputId":"b9b06c87-8577-45c1-d87e-cb5177797147"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (16512, 8)\n","y_train shape: (16512,)\n","X_test shape: (4128, 8)\n","y_test shape: (4128,)\n"]}]},{"cell_type":"markdown","source":["## **Linear Regression Implementation**"],"metadata":{"id":"_PdPierYpKtI"}},{"cell_type":"markdown","source":["Here an implementation of Linear Regression(from scratch) using only numpy is provided. The LinearRegression class allows to fit the model using the OLS method or Gradient Descent."],"metadata":{"id":"0kZcecqbpPO6"}},{"cell_type":"code","source":["class LinearRegression_scratch():\n","  \"\"\"\n","  Linear Regression.\n","\n","  Implements Linear Regression bases on OLS or Gradient Descent, as chosen by the user.\n","\n","  \"\"\"\n","\n","  def __init__(self,learning_rate=0.01,num_iterations=1000,lambda_val=0.01,regularization=False,verbose=False):\n","    \"\"\"\n","    __init__\n","\n","    Initializes the coefficients and intercept to None.\n","\n","    \"\"\"\n","    self.coefficients = None\n","    self.intercept = None\n","    self.learning_rate = learning_rate\n","    self.num_iterations = num_iterations\n","    self.lambda_val = lambda_val\n","    self.regularization = False\n","    self.verbose = verbose\n","\n","  def fit(self,X,y,method=\"ols\",learning_rate = None,num_iterations = None,lambda_val = None,verbose=None):\n","    \"\"\"\n","    Fit.\n","\n","    It fits the coefficientes w = (w1,...,wn) to the data in order to minimize the residual sum of squares between the data and the linear model.\n","    Two approaches are supported: \"ols\" or \"gradientdesc\"\n","\n","    Parameters\n","    ----------\n","    X : numpy.ndarray. Shape (n_samples,n_features)\n","        Training data.\n","\n","    y : numpy.ndarray. Shape (n_samples,)\n","        Target training data.\n","\n","    method : string.\n","             The method used to estimate the coefficients of the linear model.\n","\n","    learing_rate : float.\n","                   The learning rate used to modify the parameters.\n","\n","    num_iterations : int.\n","                     Number of iterations for the application of gradient descent.\n","\n","    lambda_val : float.\n","                 Lambda coefficient for applying regularization.\n","\n","    verbose: bool.\n","             Wether to display iteration information during training.\n","\n","    Returns\n","    -------\n","    self : object\n","           Fitted model\n","\n","    \"\"\"\n","    if verbose is not None:\n","      self.verbose=verbose\n","    if (method == \"ols\"):\n","      self.fit_ols(X,y)\n","    elif (method ==\"gradientdesc\"):\n","      self.fit_sgd(X,y,learning_rate=learning_rate,num_iterations=num_iterations,lambda_val=lambda_val)\n","    else:\n","      raise ValueError(\"Invalid fitting method. Please choose 'ols' or 'gradientdesc'.\")\n","\n","  def fit_ols(self,X,y):\n","    # Add a column of ones for the intercept term\n","    ones = np.ones((X.shape[0],1))\n","    X = np.hstack((ones, X))\n","\n","    # Calculate coefficients using the Ordinary Least Squares formula: B = X'X^(-1)X'y\n","    self.coefficients = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n","\n","  def fit_sgd(self,X,y,learning_rate,num_iterations,lambda_val):\n","\n","    if lambda_val is not None:\n","      self.regularization = True\n","      self.lambda_val = lambda_val\n","\n","    # Get the number of samples and features\n","    n_samples, n_features = X.shape\n","\n","    # Add a column of ones for the intercept term\n","    ones = np.ones((n_samples,1))\n","    X = np.hstack((ones, X))\n","\n","    # Initialize the coefficients to zeros\n","    self.intercept = 0.0\n","    self.coefficients = np.ones(n_features+1)\n","\n","    # For each iteration, generate predictions, calculate the error and update the coefficients according to the learning rate and the gradient of the loss.\n","    for iter in range(num_iterations):\n","\n","      # Generate predictions\n","      y_pred = np.dot(X,self.coefficients)\n","\n","      # Calculate the error\n","      error = y_pred - y\n","\n","      # Update intercept and coefficients\n","      if not self.regularization :\n","        self.coefficients = self.coefficients - (learning_rate * (1/n_samples) * np.dot(X.T,error))\n","      else:\n","        self.coefficients = self.coefficients - (learning_rate * (1/n_samples) * np.dot(X.T,error) + (2 * (self.lambda_val /n_samples) * self.coefficients))\n","\n","      if self.verbose:\n","        if (iter + 1) % 100 == 0:\n","          mse = self.evaluate(X[:,1:],y)\n","          print(f\"Iteration {iter + 1}: Mean Squared Error = {mse:.2f}\")\n","\n","  def predict(self,X):\n","    \"\"\"\n","    Predict.\n","\n","    Predicts the target values with the estimated linear model.\n","\n","    Parameters\n","    ----------\n","    X : numpy.ndarray. Shape (n_samples,n_features)\n","        Data to generate the prediction on.\n","\n","    Returns\n","    -------\n","    y_pred : numpy.ndarray. Shape (n_samples,1)\n","             Generated predictions\n","\n","    \"\"\"\n","    # Add a column of ones for the intercept term\n","    ones = np.ones((X.shape[0],1))\n","    X = np.hstack((ones, X))\n","\n","    # Generate predictions with y_pred = Bx\n","    y_pred = np.dot(X,self.coefficients)\n","\n","    return y_pred\n","\n","  def get_coefficients(self):\n","    \"\"\"\n","    Get coefficients.\n","\n","    Returns the estimated coefficients.\n","\n","    Returns\n","    -------\n","    coefficients: numpy.ndarray. Shape(num_features + 1,1)\n","                  Estimated coefficients and intercept.\n","    \"\"\"\n","    coefficients = np.concatenate(([self.intercept],self.coefficients))\n","    return coefficients\n","\n","  def evaluate(self,X,y):\n","    \"\"\"\n","    Evaluate.\n","\n","    Evaluate the predictions generated by the fitted model.\n","\n","    Parameters\n","    ----------\n","    X : numpy.ndarray. Shape (n_samples,n_features)\n","        Test data.\n","\n","    y : numpy.ndarray. Shape (n_samples,)\n","        Target test data.\n","\n","    Returns\n","    -------\n","    metric : float.\n","             Calculated metric.\n","    \"\"\"\n","    # Generate predictions on test data\n","    pred = self.predict(X)\n","    mse = np.mean((y - pred)**2)\n","\n","    return mse\n"],"metadata":{"id":"sXjlwzq2hQyL","executionInfo":{"status":"ok","timestamp":1687628343967,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Insantiate models\n","lr_sklearn = LinearRegression()\n","lr_ols = LinearRegression_scratch()\n","lr_sgd = LinearRegression_scratch()\n","\n","# Fit models\n","lr_sklearn.fit(X_train,y_train)\n","lr_ols.fit(X_train,y_train,method='ols')\n","lr_sgd.fit(X_train,y_train,method=\"gradientdesc\",learning_rate=0.01, num_iterations = 5000,lambda_val=0.01,verbose=False)\n","\n","# Evaluate models\n","mse_sklearn = lr_sklearn.score(X_test,y_test)\n","mse_ols = lr_ols.evaluate(X_test,y_test)\n","mse_sgd = lr_sgd.evaluate(X_test,y_test)\n","\n","print(f\"MSE for OLS(Sklearn): {mse_sklearn}\")\n","print(f\"MSE for OLS: {mse_ols}\")\n","print(f\"MSE for SGD: {mse_sgd}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tkmi4I09m-Lk","executionInfo":{"status":"ok","timestamp":1687628345797,"user_tz":-120,"elapsed":1834,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"}},"outputId":"3ea58fa8-bdb6-4cb3-aff6-b7b88a9f8c49"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE for OLS(Sklearn): 0.5757877060324511\n","MSE for OLS: 0.5558915986952444\n","MSE for SGD: 0.5600119427714327\n"]}]}]}