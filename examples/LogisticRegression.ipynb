{"cells":[{"cell_type":"markdown","metadata":{"id":"oumkc-9RhH80"},"source":["#### **Imports**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1687628343651,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"},"user_tz":-120},"id":"MjMQfw7XhEjD"},"outputs":[],"source":["import numpy as np\n","\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","from scratchml.supervised_learning.linear import LogisticRegressionSML"]},{"cell_type":"markdown","metadata":{"id":"25aLiICSnxST"},"source":["## **Data**"]},{"cell_type":"markdown","metadata":{"id":"wA0UwzcukShY"},"source":["We will be using the https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html dataset to test the model."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687628343966,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"},"user_tz":-120},"id":"jgVaNEvwnw3P"},"outputs":[],"source":["# Load the breast cancer dataset\n","cancer = load_breast_cancer()\n","X, y = cancer.data, cancer.target"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687628343967,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"},"user_tz":-120},"id":"eOKbEpMvTXxb"},"outputs":[],"source":["scaler = StandardScaler()\n","\n","# Fit the scaler to the features\n","scaler.fit(X)\n","\n","# Perform feature scaling on the features\n","X_scaled = scaler.transform(X)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687628343967,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"},"user_tz":-120},"id":"ZtNU8NXZo3GE","outputId":"b9b06c87-8577-45c1-d87e-cb5177797147"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (455, 30)\n","y_train shape: (455,)\n","X_test shape: (114, 30)\n","y_test shape: (114,)\n"]}],"source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Print the shapes of the resulting sets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"_PdPierYpKtI"},"source":["## **Linear Regression Implementation**"]},{"cell_type":"markdown","metadata":{"id":"0kZcecqbpPO6"},"source":["Here an implementation of Linear Regression(from scratch) using only numpy is provided. The LinearRegression class allows to fit the model using the OLS method or Gradient Descent."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1834,"status":"ok","timestamp":1687628345797,"user":{"displayName":"Isaac Nicolas","userId":"14840533011466190033"},"user_tz":-120},"id":"Tkmi4I09m-Lk","outputId":"3ea58fa8-bdb6-4cb3-aff6-b7b88a9f8c49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 10: Accuracy = 0.927; Loss = 0.19562\n","Iteration 20: Accuracy = 0.960; Loss = 0.13003\n","Iteration 30: Accuracy = 0.963; Loss = 0.10684\n","Iteration 40: Accuracy = 0.969; Loss = 0.09475\n","Iteration 50: Accuracy = 0.976; Loss = 0.08756\n","Iteration 60: Accuracy = 0.976; Loss = 0.08282\n","Iteration 70: Accuracy = 0.978; Loss = 0.07942\n","Iteration 80: Accuracy = 0.978; Loss = 0.07679\n","Iteration 90: Accuracy = 0.980; Loss = 0.07466\n","Iteration 100: Accuracy = 0.982; Loss = 0.07288\n","Epoch 10: Loss = 2.50505, Accuracy = 0.927\n","Epoch 20: Loss = 1.44231, Accuracy = 0.958\n","Epoch 30: Loss = 1.29049, Accuracy = 0.963\n","Epoch 40: Loss = 0.98684, Accuracy = 0.971\n","Epoch 50: Loss = 0.83502, Accuracy = 0.976\n","Epoch 60: Loss = 0.75911, Accuracy = 0.978\n","Epoch 70: Loss = 0.75911, Accuracy = 0.978\n","Epoch 80: Loss = 0.75911, Accuracy = 0.978\n","Epoch 90: Loss = 0.60729, Accuracy = 0.982\n","Epoch 100: Loss = 0.60729, Accuracy = 0.982\n"]}],"source":["# Insantiate models\n","lr_sklearn = LogisticRegression()\n","lr_gd = LogisticRegressionSML()\n","lr_sgd = LogisticRegressionSML()\n","\n","# Fit models\n","lr_sklearn.fit(X_train,y_train)\n","lr_gd.fit(X_train,y_train,method=\"gradientdesc\",lr=0.001, num_iter=100)\n","lr_sgd.fit(X_train,y_train,method=\"stochasticgradientdesc\",lr=0.001, num_iter=100)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Acc for (Sklearn): 0.9736842105263158\n","Acc for GD: 0.9824561403508771\n","Acc for SGD: 0.9824561403508771\n"]}],"source":["# Evaluate models\n","y_pred = lr_sklearn.predict(X_test)  # Predict target values for the test data\n","acc_sklearn = accuracy_score(y_test, y_pred)\n","\n","y_pred_gd = lr_gd.predict(X_test)\n","acc_gd = accuracy_score(y_test, y_pred_gd)\n","\n","y_pred_sgd = lr_gd.predict(X_test)\n","acc_sgd = accuracy_score(y_test, y_pred_sgd)\n","\n","print(f\"Acc for (Sklearn): {acc_sklearn}\")\n","print(f\"Acc for GD: {acc_gd}\")\n","print(f\"Acc for SGD: {acc_sgd}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNgw79CWOgwwEvnoj6x6ENu","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
